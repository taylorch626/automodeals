{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone\n",
    "\n",
    "### Basic Information\n",
    "\n",
    "Title: KSL AutomoDeals\n",
    "<br>\n",
    "Names: Chantel Charlebois, Taylor Hansen, Michael Paskett\n",
    "<br>\n",
    "E-mails: chantel.charlebois@utah.edu, taylor.c.hansen@utah.edu, michael.paskett@utah.edu\n",
    "<br>\n",
    "UIDS: u1043299, u0642850, u1144000\n",
    "\n",
    "### Background and Motivation\n",
    "\n",
    "Almost every person in Utah (and some neighboring states) buying a used car will visit KSL Cars classifieds to look for their new wheels. There are few resources for understanding the rough value of a used car, such as Kelly Blue Book (kbb.com), but such services cannot fully integrate the complex auto market of a local area. By storing and analyzing the prices, details, and options for a certain model or class of vehicle, a prospective buyer can evaluate how good the listed price for a vehicle actually is. With such a model, the user can estimate how much a specific car is really worth, and determine if the vehicle is worthy of a test drive.\n",
    "\n",
    "### Project Objectives\n",
    "\n",
    "Questions:\n",
    "* How well can we predict the price of a newly-listed car based on the attributes available in an advertisement?\n",
    "* Which attributes are most influential in determining the vehicle price?\n",
    "* What areas have the best price of cars?\n",
    "Aims:\n",
    "* Create a regression model that will predict the expected price of a car based on several attributes, such as:\n",
    "    * year,  seller type (dealer, private), mileage, color, title (clean/salvaged), transmission type, cylinders, fuel type, number of doors, exterior/interior condition, listing date, page views per day (when a listing has reached 7 days)\n",
    "* Create a clustered map of ‚Äúgood deals‚Äù in different regions\n",
    "\n",
    "Benefits:\n",
    "* This project could benefit anyone in the market for a used car, helping them to be informed of the potential value of a car they are interested in.\n",
    "\n",
    "### Data\n",
    "\n",
    "We will be scraping our data from queries of used cars listed on [cars.ksl.com](https://cars.ksl.com/). We have read the robots.txt files for both ksl.com and cars.ksl.com to confirm that there are no restrictions for crawling their website. We have also reviewed the terms and conditions and have similarly found no indication for rules on crawling. There used to be an undocumented API for interfacing with KSL (as of four years ago), but it is no longer publicly accessible, so we will be manually scraping with BeautifulSoup.\n",
    "\n",
    "To avoid consistently using too much bandwidth on their website, we will begin ‚Äúhistorical‚Äù data collection by saving .html pages over the course of the project so that we can parse them offline. This will form the major basis of our data set against which we can make comparisons for new queries when looking for a good deal on a newly listed used car.\n",
    "\n",
    "### Ethical Considerations\n",
    "\n",
    "Stakeholders:\n",
    "* The creators (us)\n",
    "* The seller\n",
    "* The prospective buyer\n",
    "* KSL\n",
    "\n",
    "Our incentive as creators and prospective buyers is to find good deals without having to manually spend hours searching through KSL for a good deal. For other prospective buyers, the same applies. The sellers have competing interests, as they would like to sell their car for as much as possible. KSL also has a stake in this project, as it makes revenue from ads and from sellers paying for better listings in order to make their vehicle more prominent.\n",
    "We anticipate that other ethical considerations may arise as the project progresses and details are worked out, but the above seems to encompass our understanding of the ethical issues at the time of proposal.\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "Each listing page has a fairly consistent format making scraping feasible for the large number of pages we will be analyzing. The quantities we plan to derive from our data have been listed above in the Project Objectives section. When creating a listing, the user is required to list the year, VIN, make, model, body style, mileage, title type, asking price, and ZIP code. A timestamp is also associated with each listing. Together, these are the only features we can guarantee to extract from each page. Of course, many listings have many more details listed than these which we can and plan to use.\n",
    "\n",
    "As mentioned above, data will be scraped offline from saved .html pages with BeautifulSoup and will be structured into a pandas dataframe. Dummy variables for categorical variables may be generated and concatenated to this dataframe to facilitate use of these variables. Subsequent processing will be done using built-in pandas masking to get relevant rows from the dataframe for new queries when searching recently listed used cars.\n",
    "\n",
    "### Exploratory Analysis\n",
    "\n",
    "We will visualize our data in multiple ways to check our data scraping procedures and make sure we did not incorrectly classify our data. The first basic check we will do is scrolling through the data frame for any obvious errors using the display command. We will then use the describe command to look at the descriptive statistics of each column in our dataframe. Next we will visualize the data using a scatterplot matrix in order to check the histograms of each parameter for outliers and general trends. We can also use the scatterplot matrix to explore correlations between different parameters. We will also visualize a heat map of the correlation matrix to determine which parameters are strongly correlated. This information will be used to identify potential strong predictors for the multiple linear regression and determine if any parameters are potential confounders.\n",
    "\n",
    "### Analysis Methodology\n",
    "\n",
    "#### Regression\n",
    "We will use regression to see if we can predict the price of a newly-listed used car. Our dependent variable will be list price and possible independent variables we will analyze include: year,  seller type (dealer, private), mileage, color, title (clean/salvaged), transmission type, cylinders, fuel type, number of doors, exterior/interior condition, listing date, page views per day (when a listing has reached 7 days). We will use the Python package [statsmodels](http://www.statsmodels.org/stable/index.html) to perform all regression analyses. We will do a multiple linear regression first using the parameters that had strong correlations with list price. Based off of this initial model we will adjust our multiple linear regression to only include parameters that have significant p-values for their individual coefficients. We will use a significance level of ùù∞=0.05. Our final model should have a p-value < 0.05 for the F-statistic of the overall model. We are aiming to explain at least 70% of the variance with our model and hope to get an R-squared value of 0.70 or more.\n",
    "\n",
    "#### Clustering\n",
    "We plan to cluster what we classify as a ‚Äúgood deal‚Äù in its respective geographical location and create clusters showing areas in Utah where cars are generally sold for a good deal. As we have little experience here, we expect our experience to grow from the remaining material in the course.\n",
    "\n",
    "### Project Schedule\n",
    "\n",
    "#### February 24th - 28th\n",
    "* Check data accessibility (robots.txt and terms of conditions) \n",
    "* Basic info due Wed Feb 26th\n",
    "* Project Proposal due Fri Feb 28th\n",
    "#### March 2nd - 6th\n",
    "* Download html files for all recent listings from ksl\n",
    "* Begin data scraping and create one dataframe with each row as a listing\n",
    "* Get/give peer feedback March 5th\n",
    "* Written feedback from staff by March 8th\n",
    "#### March 9th - 13th (Spring Break)\n",
    "* Finish data scraping \n",
    "* Exploratory analysis\n",
    "* Describe \n",
    "\n",
    "#### March 16th - 20th\n",
    "* Exploratory analysis\n",
    "    * Scatter Matrix\n",
    "        * Interpret histograms - check if there are any outliers that could be an error from scraping\n",
    "        * Interpret correlations\n",
    "    * Heatmap of Correlation Matrix\n",
    "        * Interpret Correlations\n",
    "\n",
    "#### March 23rd - 27th\n",
    "* Write up project milestone\n",
    "* Project milestone due March 29th \n",
    "* Acquired, cleaned data, EDA, Sketches of your analysis methods, Submit zip file with Jupyter Notebook, data, other resources.\n",
    "\n",
    "#### March 30th - April 3rd \n",
    "* Get staff feedback\n",
    "* Begin testbed for good deal predictions based on relation to scraped historical dataset\n",
    "\n",
    "#### April 6th - April 10th\n",
    "* Finalize predictive model for new listings\n",
    "* Script and film project video\n",
    "\n",
    "#### April 13th - 17th\n",
    "* Polish up repository in preparation for final submission\n",
    "* Edit and finalize project video\n",
    "* Project Due Sunday April 19th\n",
    "* Project awards April 21st\n",
    "\n",
    "### Peer Feedback\n",
    "Our Reviewers: Kyle Cornwall, Shushanna Mkrtychyan\n",
    "\n",
    "* This is pretty similar to cargurus.com and KBB. How is this different than those existing sites?\n",
    "\n",
    "* How do you know if a car has been in an accident?\n",
    "\n",
    "* Look for granularity of NADAguides and devise ways that we can \"beat\" that model.\n",
    "\n",
    "* Consider doing feature transformation when doing regression.\n",
    "\n",
    "* Can you enhance the dataset with some other website?\n",
    "\n",
    "* What features do other car valuation websites use to generate their price predictions?\n",
    "\n",
    "* Can you get Carfax info from VIN? (without breaking the bank)\n",
    "\n",
    "* Three potential classes when predicting a value (good, average, bad)\n",
    "\n",
    "* Might need to downselect the number of cars we can predict prices for since our dataset size could be limited (i.e. top 20 most frequent cars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
