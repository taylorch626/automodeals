{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate list of unique city, state combos with expected price data\n",
    "## Pull json coordinates of cities and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "cars = pd.read_pickle('../cars.pkl')\n",
    "display(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a dictionary to get full state names\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "us_state_abbrev = {abbrev: full for full, abbrev in us_state_abbrev.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a city, state column\n",
    "cars['state_full'] = cars['state'].map(us_state_abbrev)\n",
    "cars['citystate'] = cars[['city', 'state_full']].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "\n",
    "# only get non-null expected price rows\n",
    "good_cars = cars[cars.expected_price.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display list city, state combo that have cars with expected price data\n",
    "\n",
    "citystate = good_cars['citystate'].unique()\n",
    "print(f'The number of unique city, state combos is: {len(citystate)}')\n",
    "print()\n",
    "for combo in citystate:\n",
    "    print(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use city state combo to get polygons from openstreemap\n",
    "\n",
    "lefturl = 'https://nominatim.openstreetmap.org/search.php?q='\n",
    "righturl = '&polygon_geojson=1&viewbox=&format=json'\n",
    "\n",
    "# example with 1 combo\n",
    "middurl = '+'.join(citystate[0].split(' '))\n",
    "\n",
    "fullurl = lefturl + middurl + righturl\n",
    "fullurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use requests to get json data\n",
    "\n",
    "resp = requests.get(fullurl)\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a list of all urls with list comprehension\n",
    "\n",
    "fullurls = [lefturl + '+'.join(middurl.split(' ')) + righturl for middurl in citystate]\n",
    "fullurls = dict(zip(citystate, fullurls))\n",
    "fullurls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates for each city and state\n",
    "resave = 0\n",
    "\n",
    "if resave:\n",
    "    with progressbar.ProgressBar(maxval=len(fullurls)) as bar:\n",
    "        city_state_json = {}\n",
    "        i = 0\n",
    "        for loc, url in fullurls.items():\n",
    "            city_state_json[loc] = requests.get(url).json()\n",
    "            i += 1\n",
    "            bar.update(i)\n",
    "    # save location information as pickle\n",
    "    with open('city_coordinates.pkl', 'wb') as handle:\n",
    "        pickle.dump(city_state_json,handle)\n",
    "    # Test the loading\n",
    "    with open('city_coordinates.pkl','rb') as handle:\n",
    "        loaded_data = pickle.load(handle)\n",
    "    loaded_data\n",
    "    print(city_state_json == loaded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try getting zip code coordinates \n",
    "#### https://pypi.org/project/uszipcode/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with zip code module\n",
    "from uszipcode import SearchEngine # pip install uszipcode\n",
    "\n",
    "search = SearchEngine()\n",
    "\n",
    "all_zips = good_cars['zip_code'].astype('int').unique()\n",
    "coord = search.by_zipcode('84003').to_dict()['lat']\n",
    "zipdict = {zipcode: [search.by_zipcode(zipcode).to_dict()['lat'], \n",
    "                     search.by_zipcode(zipcode).to_dict()['lng']] for zipcode in all_zips}\n",
    "zipdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way to get zip code coordinates\n",
    "https://examples.opendatasoft.com/api/v1/console/datasets/1.0/search/\n",
    "https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/table/?q="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with opendatasoft api\n",
    "left_url = 'https://public.opendatasoft.com/api/records/1.0/search/?dataset=us-zip-code-latitude-and-longitude&q='\n",
    "right_url = '&facet=state&facet=timezone&facet=dst'\n",
    "\n",
    "zipcode = '84003'\n",
    "\n",
    "test = requests.get(left_url + zipcode + right_url)\n",
    "test.json()['records'][0]['fields']['geopoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resave = 0\n",
    "\n",
    "if resave:\n",
    "    zipdict_api = {}\n",
    "    with progressbar.ProgressBar(maxval=len(all_zips)) as bar:\n",
    "        i = 0\n",
    "        for zipp in all_zips:\n",
    "            full_url = left_url+str(zipp)+right_url\n",
    "            response = requests.get(full_url)\n",
    "            try:\n",
    "                loc = response.json()['records'][0]['fields']['geopoint']\n",
    "            except:\n",
    "                loc = [None, None]\n",
    "            zipdict_api.update({zipp: loc})\n",
    "            i += 1\n",
    "            bar.update(i)\n",
    "    # save\n",
    "    with open('zip_coord_api.pkl', 'wb') as handle:\n",
    "        pickle.dump(zipdict_api,handle)\n",
    "    # Test the loading\n",
    "    with open('zip_coord_api.pkl','rb') as handle:\n",
    "        loaded_data = pickle.load(handle)\n",
    "    print(zipdict_api == loaded_data)\n",
    "    loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some coordinates are missing in both datasets, but luckily there aren't any missing in both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing coordinates\n",
    "with open('zip_coord_api.pkl','rb') as handle:\n",
    "    zipdict_api = pickle.load(handle)\n",
    "    \n",
    "for zipp in zipdict_api:\n",
    "    missing = []\n",
    "    if (None in zipdict[zipp]) and (None in zipdict_api[zipp]):\n",
    "        print(f'Missing {zipp} in both dicts')\n",
    "        missing.append(zipp)\n",
    "    if (None in zipdict[zipp]):\n",
    "        print(f'Missing {zipp} in zipdict')\n",
    "    if (None in zipdict_api[zipp]): # Has more accurate coordinates, so fill in with this\n",
    "        print(f'Missing {zipp} in zipdict_api')\n",
    "        zipdict_api[zipp] = zipdict[zipp]\n",
    "\n",
    "resave = 0\n",
    "if resave:\n",
    "    with open('zip_coord_api.pkl', 'wb') as handle:\n",
    "        pickle.dump(zipdict_api, handle)\n",
    "\n",
    "zipdict_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ipyleaflet\n",
    "\n",
    "Kind of like a free version of Google Maps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ipyleaflet import Map, basemaps, GeoJSON, Popup, FullScreenControl, CircleMarker, LayerGroup\n",
    "# if above module isn't installed, do BOTH of the following:\n",
    "# pip install ipyleaflet\n",
    "# jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "\n",
    "from ipywidgets import HTML\n",
    "\n",
    "from polylabel import polylabel # if not installed, do pip install python-polylabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from https://ipyleaflet.readthedocs.io/en/latest/api_reference/basemaps.html\n",
    "\n",
    "center = [38.128, 2.588]\n",
    "zoom = 5\n",
    "\n",
    "Map(basemap=basemaps.OpenStreetMap.Mapnik, center=center, zoom=zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load a more local map\n",
    "\n",
    "center = [40.7608, -111.8910] # centered on SLC, UT\n",
    "zoom = 6\n",
    "\n",
    "Map(basemap=basemaps.OpenStreetMap.Mapnik, center=center, zoom=zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's make an interactive hoverable map!\n",
    "\n",
    "# play around with json polygon data for St. George and Hurricane, UT\n",
    "\n",
    "# instructions for where to get geojson data: https://gis.stackexchange.com/questions/183248/getting-polygon-boundaries-of-city-in-json-from-google-maps-api\n",
    "# specifically the bit about adding '&format=json' to search url\n",
    "\n",
    "# center = [40.7608, -111.8910] # SLC, UT\n",
    "# center = [39.7102, -111.8363] # Nephi, UT\n",
    "center = [37.0965, -113.5684] # St. George, UT\n",
    "zoom = 9\n",
    "m = Map(basemap=basemaps.OpenStreetMap.Mapnik, center=center, zoom=zoom)\n",
    "m.add_control(FullScreenControl())\n",
    "\n",
    "# parse St. George data\n",
    "with open('polygons\\st_george_ut.json') as city_file:\n",
    "    city_data = json.load(city_file)\n",
    "city_data_1 = city_data[-1]['geojson']\n",
    "city_data_1['varinput'] = 'mystring'\n",
    "\n",
    "# parse Hurricane data\n",
    "with open('polygons\\hurricane_ut.json') as city_file:\n",
    "    city_data = json.load(city_file)\n",
    "city_data_2 = city_data[-1]['geojson']\n",
    "city_data_2['varinput'] = 'mystring2'\n",
    "    \n",
    "def tmpfunc(event, feature):\n",
    "#     print(event)\n",
    "    \n",
    "    # remove old popup layer\n",
    "    if isinstance(m.layers[-1], Popup):\n",
    "        m.remove_layer(m.layers[-1])\n",
    "    \n",
    "    # get center of current polygon\n",
    "    txt_loc = polylabel(feature['coordinates'])[::-1]\n",
    "\n",
    "    # add a popup layer on hover over a city\n",
    "    message = HTML()\n",
    "    message.value = feature['varinput']\n",
    "    popup = Popup(location=txt_loc, child=message, close_button=False, auto_close=True, close_on_escape_key=False)\n",
    "\n",
    "    m.add_layer(popup) # add the new layer\n",
    "\n",
    "# create the GeoJSON layers (polygons overlaying each city)\n",
    "geo_json_1 = GeoJSON(data=city_data_1, style = {'color': 'red', 'opacity':1, 'weight':1.9, 'fillOpacity':0.3})\n",
    "geo_json_2 = GeoJSON(data=city_data_2, style = {'color': 'orange', 'opacity':1, 'weight':1.9, 'fillOpacity':0.3})\n",
    "geo_json_1.on_hover(tmpfunc)\n",
    "geo_json_2.on_hover(tmpfunc)\n",
    "m.add_layer(geo_json_1)\n",
    "m.add_layer(geo_json_2)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer group example from: https://ipyleaflet.readthedocs.io/en/latest/api_reference/layer_group.html#\n",
    "from ipyleaflet import (\n",
    "    Map, basemaps, basemap_to_tiles,\n",
    "    Circle, Marker, Rectangle, LayerGroup\n",
    ")\n",
    "\n",
    "toner = basemap_to_tiles(basemaps.Stamen.Toner)\n",
    "\n",
    "m = Map(layers=(toner, ), center=(50, 354), zoom=5)\n",
    "\n",
    "# Create some layers\n",
    "marker = Marker(location=(50, 354))\n",
    "circle = Circle(location=(50, 370), radius=50000, color=\"yellow\", fill_color=\"yellow\")\n",
    "rectangle = Rectangle(bounds=((54, 354), (55, 360)), color=\"orange\", fill_color=\"orange\")\n",
    "\n",
    "# Create layer group\n",
    "layer_group = LayerGroup(layers=(marker, circle))\n",
    "\n",
    "m.add_layer(layer_group)\n",
    "\n",
    "layer_group.add_layer(rectangle)\n",
    "\n",
    "# layer_group.remove_layer(circle)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try making a map for each city/state combo!\n",
    "\n",
    "Could change circle size by number of cars posted, and color by how good the deal is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experimenting with colors...\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import rgb2hex\n",
    "import random\n",
    "coolwarm = cm.get_cmap('coolwarm',5)\n",
    "rgb2hex(coolwarm(0.5))\n",
    "random.randint(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#d7191c','#fdae61','#ffffbf','#a6d96a','#1a9641']\n",
    "colors = ['red', 'orange', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5a13732c604424b0b0a71c87a74330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[39.321, -111.0937], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utah_center = [39.3210, -111.0937]\n",
    "zoom = 6\n",
    "m = Map(basemap=basemaps.OpenStreetMap.Mapnik, center=utah_center, zoom=zoom)\n",
    "m.add_control(FullScreenControl())\n",
    "\n",
    "# load zip code coordinates\n",
    "with open('zip_coord_api.pkl','rb') as handle:\n",
    "    zip_coord = pickle.load(handle)\n",
    "\n",
    "# create a layer group \n",
    "layer_group = LayerGroup()\n",
    "for zipp, coord in zip_coord.items():\n",
    "    circle = CircleMarker()\n",
    "    circle.location = coord\n",
    "    circle.radius = random.randint(1,10)\n",
    "    circle.weight = 2\n",
    "    circle.opacity = 0.8\n",
    "    color = random.randint(0,2)\n",
    "    circle.color = colors[color]\n",
    "    circle.fill_color = colors[color]\n",
    "    circle.fill_opacity = 0.3\n",
    "    layer_group.add_layer(circle)\n",
    "    \n",
    "\n",
    "m.add_layer(layer_group)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gmaps (Google Maps)\n",
    "\n",
    "Note: to avoid the watermark, you have to sign up for a billing service for your API account as of June 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from gmaps documentation at https://jupyter-gmaps.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "import gmaps\n",
    "import gmaps.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_df = gmaps.datasets.load_dataset_as_df('earthquakes')\n",
    "earthquake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = earthquake_df[['latitude', 'longitude']]\n",
    "weights = earthquake_df['magnitude']\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(gmaps.heatmap_layer(locations, weights=weights))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_coordinates = (40.75, -74.00)\n",
    "gmaps.figure(center=new_york_coordinates, zoom_level=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "463.85px",
    "left": "1545px",
    "right": "20px",
    "top": "138px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
